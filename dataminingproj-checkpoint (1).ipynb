{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c8fe1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 46.666666666666664 %\n",
      "Precision: 0.775\n",
      "Recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/LabeledScoredTweets.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c01278b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.333333333333336 %\n",
      "Precision: 0.8\n",
      "Recall: 0.5161290322580645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/LabeledScoredTweets2.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ce2fceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.333333333333336 %\n",
      "Precision: 0.575\n",
      "Recall: 0.5609756097560976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/VaterScoredTweets.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7894026f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.64864864864865 %\n",
      "Precision: 0.8157894736842105\n",
      "Recall: 0.5081967213114754\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/LabeledScoredTweets.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "# Shift the 'Expected_Value' up by one row\n",
    "merged_data['Expected_Value'] = merged_data['Expected_Value'].shift(1)\n",
    "\n",
    "# Drop the last row\n",
    "merged_data = merged_data[:-1]\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy day after:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3e5a1465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.33333333333333 %\n",
      "Precision: 0.7692307692307693\n",
      "Recall: 0.4918032786885246\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/LabeledScoredTweets2.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "\n",
    "# Shift the 'Expected_Value' up by one row\n",
    "merged_data['Expected_Value'] = merged_data['Expected_Value'].shift(1)\n",
    "\n",
    "# Drop the last row\n",
    "mmerged_data = merged_data[:-1]\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy day after:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4aa974e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.054054054054056 %\n",
      "Precision: 0.6052631578947368\n",
      "Recall: 0.5609756097560976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/VaterScoredTweets.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "# Shift the 'Expected_Value' up by one row\n",
    "merged_data['Expected_Value'] = merged_data['Expected_Value'].shift(1)\n",
    "\n",
    "# Drop the last row\n",
    "merged_data = merged_data[:-1]\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy day after:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "71a2819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 5 days after: 36.0 %\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.43103448275862066\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/LabeledScoredTweets.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "\n",
    "# Shift the 'Expected_Value' up by one row\n",
    "merged_data['Expected_Value'] = merged_data['Expected_Value'].shift(5)\n",
    "\n",
    "# Drop the last row\n",
    "mmerged_data = merged_data[:-1]\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy 5 days after:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3d9e746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 5 days after: 36.0 %\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.43103448275862066\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/LabeledScoredTweets2.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "\n",
    "# Shift the 'Expected_Value' up by one row\n",
    "merged_data['Expected_Value'] = merged_data['Expected_Value'].shift(5)\n",
    "\n",
    "# Drop the last row\n",
    "mmerged_data = merged_data[:-1]\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy 5 days after:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c70ef4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 5 days after: 40.54054054054054 %\n",
      "Precision: 0.5294117647058824\n",
      "Recall: 0.43902439024390244\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_first_column(dataframe):\n",
    "    # Group the dataframe by the first column and aggregate the second column\n",
    "    aggregated_df = dataframe.groupby(dataframe.columns[0]).agg(list).reset_index()\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/VaterScoredTweets.csv')\n",
    "\n",
    "# Call the function to aggregate by the first column\n",
    "aggregated_data = data.groupby(data.columns[0])[data.columns[1]].sum().reset_index()\n",
    "aggregated_data.to_csv('aggregated_data.csv', index=False)\n",
    "\n",
    "#print(aggregated_data)\n",
    "\n",
    "# Read the aggregated dataset\n",
    "aggregated_data = pd.read_csv('aggregated_data.csv')\n",
    "\n",
    "# Read the NASDAC index dataset\n",
    "nasdac_data = pd.read_csv('C:/Users/debtn/OneDrive/Desktop/datamining/NASDACindex.csv')\n",
    "\n",
    "# Merge the two datasets based on the common values in the first column\n",
    "merged_data = pd.merge(aggregated_data, nasdac_data, on=aggregated_data.columns[0])\n",
    "\n",
    "#print(merged_data)\n",
    "\n",
    "# Compare the second column values and create a new column for expected values\n",
    "merged_data['Expected_Value'] = (merged_data[aggregated_data.columns[1]] > 0).astype(int)\n",
    "\n",
    "# Shift the 'Expected_Value' up by one row\n",
    "merged_data['Expected_Value'] = merged_data['Expected_Value'].shift(5)\n",
    "\n",
    "# Drop the last row\n",
    "merged_data = merged_data[:-1]\n",
    "\n",
    "# Calculate the accuracy by comparing the actual values with the expected values\n",
    "accuracy = (merged_data[nasdac_data.columns[1]] == merged_data['Expected_Value']).mean() * 100\n",
    "\n",
    "# Calculate precision\n",
    "true_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "false_positive = ((merged_data[nasdac_data.columns[1]] == 1) & (merged_data['Expected_Value'] == 0)).sum()\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "# Calculate recall\n",
    "false_negative = ((merged_data[nasdac_data.columns[1]] == 0) & (merged_data['Expected_Value'] == 1)).sum()\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print('Accuracy 5 days after:', accuracy, '%')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1220f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
